{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4e5f4dc-b6ec-469a-9de8-7d31a2987fd4",
   "metadata": {},
   "source": [
    "### üß© **Install required libraries**\n",
    "\n",
    "#### **What this does**\n",
    "\n",
    "* `pip install` ‚Üí installs Python packages.\n",
    "* `google-genai` ‚Üí Google Gemini API client library.\n",
    "* `python-dotenv` ‚Üí allows loading secrets (like API keys) from a `.env` file.\n",
    "* `-q` ‚Üí quiet mode, reduces installation logs.\n",
    "\n",
    "üìå **Why this is needed:**\n",
    "Your app depends on the Gemini client and the dotenv loader.\n",
    "This cell ensures they‚Äôre available in the notebook environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94744257-8070-4405-8ce6-7c83c729a0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q google-genai python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc71681-ba4b-47aa-8658-8622d64cec48",
   "metadata": {},
   "source": [
    "### üß© **Import necessary modules**\n",
    "\n",
    "#### **What this does**\n",
    "\n",
    "* `load_dotenv` ‚Üí loads variables from `.env` file into your code.\n",
    "* `genai` + `types` ‚Üí required to create the Gemini client and send requests.\n",
    "* `display, Markdown` ‚Üí formats AI output nicely inside the notebook.\n",
    "\n",
    "üìå **Why this matters:**\n",
    "These imports give your notebook all the tools it needs to communicate with Gemini and show clean results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294c73a5-e825-404b-a025-67f78a698037",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc79c77-7872-41b5-9548-fbbc2b6a9e46",
   "metadata": {},
   "source": [
    "### üß© **Load environment variables**\n",
    "\n",
    "#### **What this does**\n",
    "\n",
    "* Looks for a file named `.env` in the project folder.\n",
    "* Loads key-value pairs (like `GEMINI_API_KEY=...`) into Python‚Äôs environment.\n",
    "\n",
    "üìå **Why this matters:**\n",
    "This allows you to keep API keys **out of your code**, improving security and best practices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026990e2-efa1-487e-82b9-42674c88d028",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6997b663-ae44-4dc8-852d-241847022b75",
   "metadata": {},
   "source": [
    "### üß© **Create the Gemini client**\n",
    "\n",
    "#### **What this does**\n",
    "\n",
    "* Creates a client object to talk to Gemini.\n",
    "* The client automatically reads the API key from the environment (loaded earlier).\n",
    "\n",
    "üìå **Why this matters:**\n",
    "Without this client, you cannot make requests to the Gemini API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc8c97c-8fd6-44b3-9f8c-1c9dd8bb6744",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc43cd1f-2ea2-48a7-844a-64a151fdf9ec",
   "metadata": {},
   "source": [
    "### üß© **Select which Gemini model to use**\n",
    "\n",
    "#### **What this does**\n",
    "\n",
    "* Stores the model name in a variable.\n",
    "* Easy to change later if you want to switch to another model (e.g., `gemini-2.0-pro`).\n",
    "\n",
    "üìå **Why this matters:**\n",
    "Model selection influences speed, cost, and output quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad58d152-e522-478f-9123-2bd00bb9ae2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'gemini-2.5-flash'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12575ea6-33d7-4b63-b180-b37f47c75538",
   "metadata": {},
   "source": [
    "### üß© **Set system prompt and model parameters**\n",
    "\n",
    "#### **What these do**\n",
    "\n",
    "* `system_prompt` ‚Üí tells the AI its role and behavior (like a personality or instructions).\n",
    "* `temperature_setting`\n",
    "\n",
    "  * Controls creativity\n",
    "  * **0 = predictable**, **1 = creative**, **>1 = more random**\n",
    "* `thinking_budget_setting` ‚Üí used for ‚Äústructured thinking‚Äù mode; `0` disables it.\n",
    "\n",
    "üìå **Why this matters:**\n",
    "These settings shape how the AI responds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdd07e3-572c-420b-aaf1-7ea5d9d04ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are SimplifAIy, an AI assistant whose job is to explain complex topics in a way that even a beginner can understand.\n",
    "\n",
    "Follow these rules:\n",
    "1. Break the topic into simple parts.\n",
    "2. Explain using everyday language, avoiding jargon unless necessary.\n",
    "3. Provide analogies and relatable examples.\n",
    "4. Include a step-by-step explanation when useful.\n",
    "5. Start with a short summary, then go deeper.\n",
    "6. Provide real-world applications to reinforce understanding.\n",
    "7. If the user asks about a very advanced topic, progressively simplify it.\n",
    "8. Never overwhelm the user ‚Äî clarity over completeness.\n",
    "9. Format the answer using:\n",
    "   - Headings\n",
    "   - Bullet points\n",
    "   - Short paragraphs\n",
    "\n",
    "Your goal: make the user say ‚ÄúOh, now I get it!\"\n",
    "\"\"\"\n",
    "temperature_setting = 1.0\n",
    "thinking_budget_setting = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198b1f62-0ec8-44bb-8500-2cf05f4a97e3",
   "metadata": {},
   "source": [
    "### üß© **Ask the user for a topic**\n",
    "\n",
    "#### **What this does**\n",
    "\n",
    "* **A `while True` loop** keeps asking the user for input until a valid prompt is provided.\n",
    "   This ensures your app never sends an empty request to the AI.\n",
    "* `user_input = input(...)`\n",
    "   Displays a friendly question asking for a topic the user wants simplified.\n",
    "* `user_input.strip()` Removes extra spaces in the input to detect whether the user actually typed something meaningful\n",
    "* If the input contains **any real text**, the loop ends with `break`.\n",
    "* If the input is **empty or only spaces**, the program prints a warning and asks again.\n",
    "\n",
    "üìå **Why this matters:**\n",
    "* Prevents accidental empty prompts being sent to the AI (which would produce bad or meaningless responses).\n",
    "* Makes the application more user-friendly and error-proof."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da34a498-bad0-4c35-b2a5-2100ff657550",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    user_input = input(\"\"\"Hey there! Got a topic that feels confusing or complex? Tell me, and I‚Äôll simplify it for you!\n",
    "    Input: \"\"\")\n",
    "    \n",
    "    if user_input.strip():\n",
    "        # A valid prompt was entered, exit the loop\n",
    "        break\n",
    "    else:\n",
    "        # Invalid (empty or whitespace only) prompt entered, prompt again\n",
    "        print(\"Input cannot be empty. Please enter a valid prompt.\")\n",
    "        \n",
    "prompt = f\"\"\"Simplify the following topic as clearly as possible:\n",
    "\n",
    "{user_input}\n",
    "\n",
    "Make sure your explanation includes:\n",
    "- A simple summary (2‚Äì3 sentences)\n",
    "- A step-by-step breakdown\n",
    "- One analogy\n",
    "- One real-world example\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3efb0a-4994-4c0a-8535-d3d36df39da2",
   "metadata": {},
   "source": [
    "### üß© **Generate the AI response**\n",
    "\n",
    "#### **What this does**\n",
    "\n",
    "1. Sends the user‚Äôs topic to Gemini.\n",
    "2. Applies your configuration (system prompt + temperature).\n",
    "3. Asks the model to generate simplified content.\n",
    "4. Stores the output in `response`.\n",
    "\n",
    "üìå **Why this matters:**\n",
    "This is the core of your AI application ‚Äî the actual call to Gemini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72b1456-c07f-4ca7-9160-223357d98523",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.models.generate_content(\n",
    "    model=MODEL_NAME,\n",
    "    contents=[prompt],\n",
    "    config=types.GenerateContentConfig(\n",
    "        system_instruction=system_prompt,\n",
    "        temperature=temperature_setting,\n",
    "        thinking_config=types.ThinkingConfig(\n",
    "            thinking_budget=thinking_budget_setting\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2fc2a6-70ab-483d-b524-975aa3557599",
   "metadata": {},
   "source": [
    "### üß© **Display the AI output**\n",
    "\n",
    "#### **What this does**\n",
    "\n",
    "* Takes the AI‚Äôs text output.\n",
    "* Converts it into Markdown (clean headings, bold text, bullet points).\n",
    "* Displays it visually inside the notebook.\n",
    "\n",
    "üìå **Why this matters:**\n",
    "It makes the AI‚Äôs answer look clear and readable instead of plain text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4086e2ac-0ffa-47b4-b7f3-1109b03ece63",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(response.text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
